\chapter{前言} 
\label{ch:preface}

\section*{本书定位}

\begin{content}

这是一本剖析\ascii{TensorFlow}内核工作原理的书籍，并非讲述如何使用\ascii{TensorFlow}构建机器学习模型，也不会讲述应用\ascii{TensorFlow}的最佳实践。本书将通过剖析\ascii{TensorFlow}源代码的方式，揭示\ascii{TensorFlow}的系统架构、领域模型、工作原理、及其实现模式等相关内容，以便揭示内在的知识。

\end{content}


\section*{面向的读者}

\begin{content}

本书假设读者已经了解机器学习相关基本概念与理论，了解机器学习相关的基本方法论；同时，假设读者熟悉\ascii{Python, C++}等程序设计语言。

本书适合于渴望深入了解\ascii{TensorFlow}内核设计，期望改善\ascii{TensorFlow}系统设计和性能优化，及其探究\ascii{TensorFlow}关键技术的设计和实现的系统架构师、\ascii{AI}算法工程师、和\ascii{AI}软件工程师。

\end{content}

\section*{阅读方式}

\begin{content}

初次阅读本书，推荐循序渐进的阅读方式；对于高级用户，可以选择感兴趣的章节阅读。首次使用\ascii{TensorFlow}时，推荐从源代码完整地构建一次\ascii{TensorFlow}，以便了解系统的构建方式，及其理顺所依赖的基本组件库。

另外，推荐使用\ascii{TensorFlow}亲自实践一些具体应用，以便加深对\ascii{TensorFlow}系统行为的认识和理解，熟悉常见\ascii{API}的使用方法和工作原理。强烈推荐阅读本书的同时，阅读\ascii{TensorFlow}关键代码；关于阅读代码的最佳实践，请查阅本书附录\ascii{A}的内容。

\end{content}

\section*{版本说明}

\begin{content}

本书写作时，\ascii{TensorFlow}稳定发布版本为\ascii{1.2}。不排除本书讲解的部分\ascii{API}将来被废弃，也不保证某些系统实现在未来版本发生变化，甚至被删除。

同时，为了更直接的阐述问题的本质，书中部分代码做了局部的重构；删除了部分异常处理分支，或日志打印，甚至是某些可选参数列表。但是，这样的局部重构，不会影响读者理解系统的主要行为特征，更有利于读者掌握系统的工作原理。

同时，为了简化计算图的表达，本书中的计算图并非来自\ascii{TensorBoard}，而是采用简化了的，等价的图结构。同样地，简化了的图结构，也不会降低读者对真实图结构的认识和理解。

\end{content}

\section*{英语术语}

\begin{content}

因为我所撰写的文章，是供相关专业人士阅读，而非科普读物，因此在书中保留专业领域中朗朗上口的英语术语，故意不做翻译。例如，书中直接使用\ascii{OP}的术语，而不是将其翻译为「操作」。

但是，这会造成大面积的中英混杂的表达方式。幸运的是，绝对部分所使用的英语术语都是名词，极少出现动词或者形容词。但是，无论如何都不会丢失原本的主体语义和逻辑。

万事都有例外，对于无歧义的，表达简短，且语义明确的术语，会使用中文术语表示。特殊地，对于中文术语表达存在歧义时，会同时标注中文术语和英语术语。例如，检查点(\ascii{Checkpoint})，协调器(\ascii{Coordinator})。

一般地，无歧义的中文术语表定义在\reftbl{glossary}。

\begin{table}[!htb]
\resizebox{0.95\textwidth}{!} {
\begin{tabular*}{1.2\textwidth}{@{}ll@{}}
\toprule
\ascii{英文} & \ascii{中文} \\
\midrule
\ascii{Variable} & \ascii{变量，参数} \\
\ascii{Session} & \ascii{会话} \\ 
\ascii{Device} & \ascii{设备} \\ 
\bottomrule
\end{tabular*}
}
\caption{规范约定}
\label{tbl:glossary}
\end{table}

\end{content}

\section*{代码重构}

\begin{content}

在\ascii{IDE}里阅读代码，可以借助于上下文信息协助程序员阅读代码。但在书中展示的源代码，由于篇幅受限，再加之缺乏上下文的缘故，代码阅读的效果将大大折扣。

一般地，为了更好地协助读者加快代码理解的速度和质量，常见的办法包括代码批注，内容讲解，算法描述，数据结构描述。但在作者的价值观中，与其批注过多的代码注释，不如重构代码，让代码直接表达语义。因此在本书中，作者另辟蹊径，尝试局部的代码重构，增加代码的可理解性。

例如，在\code{distributed\_runtime/master.cc}中，存在如下代码片段，上半部分的语义就是按照\code{session\_handle}线性查找相应的\code{MasterSession}示例。

\begin{leftbar}
\begin{c++}
void Master::ExtendSession(
    const ExtendSessionRequest* req,
    ExtendSessionResponse* resp, MyClosure done) {
  // Find master session by session handle.
  mu_.lock();
  MasterSession* session = nullptr;
  session = gtl::FindPtrOrNull(sessions_, req->session_handle());
  if (session == nullptr) {
    mu_.unlock();
    done(errors::Aborted(
         "Session ", req->session_handle(), " is not found."));
    return;
  }
  session->Ref();
  mu_.unlock();

  SchedClosure([session, req, resp, done]() {
    Status status = ValidateExternalGraphDefSyntax(req->graph_def());
    if (status.ok()) {
      status = session->Extend(req, resp);
    }
    session->Unref();
    done(status);
  });
}

void Master::PartialRunSetup(
    const PartialRunSetupRequest* req,
    PartialRunSetupResponse* resp, MyClosure done) {
  // Find master session by session handle.
  mu_.lock();
  MasterSession* session = nullptr;
  session = gtl::FindPtrOrNull(sessions_, req->session_handle());
  if (session == nullptr) {
    mu_.unlock();
    done(errors::Aborted(
         "Session ", req->session_handle(), " is not found."));
    return;
  }
  session->Ref();
  mu_.unlock();

  SchedClosure([this, session, req, resp, done]() {
    Status s = session->PartialRunSetup(req, resp);
    session->Unref();
    done(s);
  });
}
\end{c++}
\end{leftbar}

如果在此处尝试提取函数，直接地表达原有的语义。重构后的效果，不仅删除了冗余的注释，增强了代码的可理解性，而且间接消除了两者之间的重复代码。当然，为了保证本书中的代码示例与社区代码仓库的一致，作者会争取将重构后的代码合入\ascii{master}分支。

\begin{leftbar}
\begin{c++}
void Master::ExtendSession(
    const ExtendSessionRequest* req,
    ExtendSessionResponse* resp, MyClosure done) {
  auto session = FindMasterSession(req->session_handle());
  if (session == nullptr) {
    done(AbortedError(req));
    return;
  }

  SchedClosure([session, req, resp, done]() {
    Status status = ValidateExternalGraphDefSyntax(req->graph_def());
    if (status.ok()) {
      status = session->Extend(req, resp);
    }
    session->Unref();
    done(status);
  });
}

void Master::PartialRunSetup(
    const PartialRunSetupRequest* req,
    PartialRunSetupResponse* resp, MyClosure done) {
  auto session = FindMasterSession(req->session_handle());
  if (session == nullptr) {
    done(AbortedError(req));
    return;
  }

  SchedClosure([this, session, req, resp, done]() {
    Status s = session->PartialRunSetup(req, resp);
    session->Unref();
    done(s);
  });
}
\end{c++}
\end{leftbar}

\end{content}

\section*{在线帮助}

\begin{content}

为了更好地与读者交流，已在\ascii{Github}上建立了勘误表，及其相关补充说明。由于个人经验与能力有限，在有限的时间内难免犯错。如果读者在阅读过程中，如果发现相关错误，请帮忙提交\ascii{Pull Request}，避免他人掉入相同的陷阱之中，让知识分享变得更加通畅，更加轻松，我将不甚感激。

同时，欢迎关注我的简书。我将持续更新相关的文章，与更多的朋友一起学习和进步。

\begin{enum}
  \eitem{\ascii{Github: \script{\url{https://github.com/horance-liu/tensorflow-internals-errors}}}}
  \eitem{\ascii{简书：\script{\url{http://www.jianshu.com/u/49d1f3b7049e}}}}
\end{enum}

\end{content}

\section*{致谢}

\begin{content}

感谢我的太太刘梅红，在工作之余完成对本书的审校，并提出了诸多修改的意见。

\end{content}
